{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHC8c8PInzkx"
      },
      "source": [
        "## Skill Dictionary\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EYnY3DTNnzlM"
      },
      "outputs": [],
      "source": [
        "skill_lemma_dict = {\n",
        "    # Programming Languages\n",
        "    \"python\": [\"python\", \"py\", \"pandas\", \"numpy\", \"scipy\", \"flask\", \"django\"],\n",
        "    \"java\": [\"java\", \"jvm\", \"spring\", \"hibernate\", \"maven\", \"gradle\"],\n",
        "    \"javascript\": [\"javascript\", \"js\", \"node.js\", \"react.js\", \"vue.js\", \"angular\", \"typescript\"],\n",
        "    \"csharp\": [\"c#\", \".net\", \"asp.net\", \"entity framework\"],\n",
        "    \"c++\": [\"c++\", \"cpp\", \"qt\", \"boost\"],\n",
        "    \"php\": [\"php\", \"laravel\", \"symfony\"],\n",
        "    \"ruby\": [\"ruby\", \"rails\"],\n",
        "    \"go\": [\"go\", \"golang\"],\n",
        "    \"swift\": [\"swift\", \"ios\"],\n",
        "    \"kotlin\": [\"kotlin\", \"android\"],\n",
        "    \"scala\": [\"scala\", \"akka\", \"play framework\"],\n",
        "    \"rust\": [\"rust\"],\n",
        "    \"perl\": [\"perl\"],\n",
        "\n",
        "    # Frameworks and Libraries\n",
        "    \"react\": [\"react\", \"react.js\", \"react native\"],\n",
        "    \"angular\": [\"angular\"],\n",
        "    \"vue\": [\"vue\", \"vue.js\"],\n",
        "    \"jquery\": [\"jquery\"],\n",
        "    \"bootstrap\": [\"bootstrap\"],\n",
        "    \"express\": [\"express\"],\n",
        "    \"spring boot\": [\"spring boot\"],\n",
        "    \"tensorflow\": [\"tensorflow\"],\n",
        "    \"keras\": [\"keras\"],\n",
        "    \"pytorch\": [\"pytorch\"],\n",
        "    \"scikit-learn\": [\"scikit-learn\"],\n",
        "\n",
        "    # Databases\n",
        "    \"sql\": [\"sql\", \"mysql\", \"postgresql\", \"oracle\", \"sql server\"],\n",
        "    \"nosql\": [\"nosql\", \"mongodb\", \"cassandra\", \"redis\", \"neo4j\", \"couchdb\"],\n",
        "    \"mysql\": [\"mysql\"],\n",
        "    \"postgresql\": [\"postgresql\"],\n",
        "    \"mongodb\": [\"mongodb\"],\n",
        "    \"redis\": [\"redis\"],\n",
        "    \"sqlite\": [\"sqlite\"],\n",
        "    \"oracle\": [\"oracle\"],\n",
        "    \"snowflake\": [\"snowflake\"],\n",
        "    \"redshift\": [\"redshift\"],\n",
        "    \"greenplum\": [\"greenplum\"],\n",
        "    \"teradata\": [\"teradata\"],\n",
        "\n",
        "    # DevOps and Cloud Platforms\n",
        "    \"aws\": [\"aws\", \"ec2\", \"s3\", \"lambda\", \"rds\"],\n",
        "    \"azure\": [\"azure\", \"azure devops\"],\n",
        "    \"google cloud\": [\"google cloud\", \"gcp\", \"app engine\", \"kubernetes engine\"],\n",
        "    \"docker\": [\"docker\", \"docker-compose\"],\n",
        "    \"kubernetes\": [\"kubernetes\", \"k8s\"],\n",
        "    \"jenkins\": [\"jenkins\"],\n",
        "    \"travis ci\": [\"travis ci\"],\n",
        "    \"gitlab ci\": [\"gitlab ci\"],\n",
        "    \"circleci\": [\"circleci\"],\n",
        "\n",
        "    # Web Technologies\n",
        "    \"html\": [\"html\"],\n",
        "    \"css\": [\"css\", \"sass\", \"less\"],\n",
        "    \"rest api\": [\"rest\", \"restful\", \"json\", \"xml\"],\n",
        "    \"graphql\": [\"graphql\"],\n",
        "\n",
        "    # Software Development Methodologies\n",
        "    \"agile\": [\"agile\", \"scrum\", \"kanban\"],\n",
        "    \"devops\": [\"devops\", \"site reliability\"],\n",
        "\n",
        "    # Soft Skills\n",
        "    \"leadership\": [\"leadership\", \"management\"],\n",
        "    \"communication\": [\"communication\", \"teamwork\"],\n",
        "    \"problem-solving\": [\"problem-solving\", \"analytical skills\"],\n",
        "    \"adaptability\": [\"adaptability\", \"flexibility\"],\n",
        "    \"teamwork\": [\"teamwork\"],\n",
        "    \"leadership\": [\"leadership\"],\n",
        "    \"project management\": [\"project management\", \"pm\"],\n",
        "    \"creativity\": [\"creativity\"],\n",
        "    \"critical thinking\": [\"critical thinking\"],\n",
        "    \"emotional intelligence\": [\"emotional intelligence\", \"eq\"],\n",
        "    \"negotiation\": [\"negotiation\"],\n",
        "    \"decision making\": [\"decision making\"],\n",
        "\n",
        "    # Machine Learning\n",
        "    \"machine learning\": [\"machine learning\", \"ml\"],\n",
        "    \"deep learning\": [\"deep learning\", \"dl\"],\n",
        "    \"reinforcement learning\": [\"reinforcement learning\", \"rl\"],\n",
        "    \"supervised learning\": [\"supervised learning\"],\n",
        "    \"unsupervised learning\": [\"unsupervised learning\"],\n",
        "    \"semi-supervised learning\": [\"semi-supervised learning\"],\n",
        "    \"natural language processing\": [\"natural language processing\", \"nlp\"],\n",
        "    \"computer vision\": [\"computer vision\"],\n",
        "    \"speech recognition\": [\"speech recognition\"],\n",
        "    \"anomaly detection\": [\"anomaly detection\"],\n",
        "    \"generative adversarial networks\": [\"gan\", \"generative adversarial networks\"],\n",
        "    \"transfer learning\": [\"transfer learning\"],\n",
        "    \"feature engineering\": [\"feature engineering\"],\n",
        "    \"model optimization\": [\"model optimization\"],\n",
        "    \"model deployment\": [\"model deployment\"],\n",
        "    \"edge AI\": [\"edge ai\", \"edge computing\"],\n",
        "    \"federated learning\": [\"federated learning\"],\n",
        "    \"explainable AI\": [\"explainable ai\", \"xai\"],\n",
        "\n",
        "    # ML Frameworks and Libraries\n",
        "    \"tensorflow\": [\"tensorflow\", \"tf\"],\n",
        "    \"keras\": [\"keras\"],\n",
        "    \"pytorch\": [\"pytorch\"],\n",
        "    \"scikit-learn\": [\"scikit-learn\", \"sklearn\"],\n",
        "    \"pandas\": [\"pandas\"],\n",
        "    \"numpy\": [\"numpy\"],\n",
        "    \"scipy\": [\"scipy\"],\n",
        "    \"matplotlib\": [\"matplotlib\"],\n",
        "    \"seaborn\": [\"seaborn\"],\n",
        "    \"xgboost\": [\"xgboost\"],\n",
        "    \"lightgbm\": [\"lightgbm\"],\n",
        "    \"opencv\": [\"opencv\"],\n",
        "    \"spacy\": [\"spacy\"],\n",
        "    \"nltk\": [\"nltk\"],\n",
        "    \"gensim\": [\"gensim\"],\n",
        "    \"huggingface\": [\"huggingface\", \"transformers\"],\n",
        "    \"fastai\": [\"fastai\"],\n",
        "    \"caffe\": [\"caffe\"],\n",
        "    \"theano\": [\"theano\"],\n",
        "    \"dlib\": [\"dlib\"],\n",
        "    \"mlflow\": [\"mlflow\"],\n",
        "    \"pycaret\": [\"pycaret\"],\n",
        "    \"streamlit\": [\"streamlit\"],\n",
        "    \"dash\": [\"dash\"],\n",
        "\n",
        "    # Time Series Analysis & Forecasting\n",
        "    \"time series\": [\"time series\", \"time series analysis\"],\n",
        "    \"arima\": [\"arima\"],\n",
        "    \"prophet\": [\"prophet\"],\n",
        "    \"lstm\": [\"lstm\"],\n",
        "\n",
        "    # Deep Learning Specific Technologies\n",
        "    \"convolutional neural networks\": [\"cnn\", \"convolutional neural networks\"],\n",
        "    \"recurrent neural networks\": [\"rnn\", \"recurrent neural networks\"],\n",
        "    \"long short-term memory\": [\"lstm\"],\n",
        "    \"transformers\": [\"transformers\"],\n",
        "    \"bert\": [\"bert\"],\n",
        "    \"gpt\": [\"gpt\", \"gpt-2\", \"gpt-3\"],\n",
        "\n",
        "    # Visualization and Reporting Tools\n",
        "    \"tableau\": [\"tableau\"],\n",
        "    \"power bi\": [\"power bi\"],\n",
        "    \"qlik\": [\"qlik\", \"qlikview\", \"qliksense\"],\n",
        "    \"looker\": [\"looker\"],\n",
        "\n",
        "    # Big Data\n",
        "    \"big data\": [\"big data\"],\n",
        "    \"hadoop\": [\"hadoop\"],\n",
        "    \"spark\": [\"spark\"],\n",
        "    \"kafka\": [\"kafka\"],\n",
        "    \"hive\": [\"hive\"],\n",
        "    \"flink\": [\"flink\"],\n",
        "    \"elastic search\": [\"elastic search\", \"elasticsearch\"],\n",
        "    \"solr\": [\"solr\"],\n",
        "    \"cassandra\": [\"cassandra\"],\n",
        "    \"hbase\": [\"hbase\"],\n",
        "    \"neo4j\": [\"neo4j\"],\n",
        "\n",
        "    # Cloud and DevOps\n",
        "    \"aws\": [\"aws\", \"amazon web services\"],\n",
        "    \"azure\": [\"azure\"],\n",
        "    \"gcp\": [\"gcp\", \"google cloud platform\"],\n",
        "    \"docker\": [\"docker\"],\n",
        "    \"kubernetes\": [\"kubernetes\", \"k8s\"],\n",
        "    \"jenkins\": [\"jenkins\"],\n",
        "    \"ci/cd\": [\"ci/cd\", \"continuous integration\", \"continuous deployment\"],\n",
        "    \"terraform\": [\"terraform\"],\n",
        "    \"ansible\": [\"ansible\"],\n",
        "    \"cloudformation\": [\"cloudformation\"],\n",
        "    \"openstack\": [\"openstack\"],\n",
        "\n",
        "    # Data Engineering and ETL Tools\n",
        "    \"airflow\": [\"airflow\"],\n",
        "    \"luigi\": [\"luigi\"],\n",
        "    \"talend\": [\"talend\"],\n",
        "    \"pentaho\": [\"pentaho\"],\n",
        "    \"informatica\": [\"informatica\"],\n",
        "\n",
        "    # Miscellaneous\n",
        "    \"git\": [\"git\", \"version control\", \"svn\"],\n",
        "    \"project management\": [\"jira\", \"trello\", \"asana\"],\n",
        "    \"ui/ux\": [\"ui\", \"ux\", \"user interface\", \"user experience\"],\n",
        "    \"cybersecurity\": [\"cybersecurity\", \"penetration testing\", \"encryption\"],\n",
        "    \"data analysis\": [\"data analysis\", \"excel\", \"power bi\", \"tableau\", \"data analytics\"],\n",
        "    \"data visualization\": [\"data visualization\"],\n",
        "    \"data mining\": [\"data mining\"],\n",
        "    \"statistical analysis\": [\"statistical analysis\", \"statistics\"],\n",
        "    \"ethics in AI\": [\"ethics in ai\", \"ai ethics\"],\n",
        "    \"quantum computing\": [\"quantum computing\"],\n",
        "    \"blockchain\": [\"blockchain\"],\n",
        "    \"augmented reality\": [\"augmented reality\", \"ar\"],\n",
        "    \"virtual reality\": [\"virtual reality\", \"vr\"],\n",
        "    \"internet of things\": [\"iot\", \"internet of things\"],\n",
        "    \"robotics\": [\"robotics\"],\n",
        "    \"drones\": [\"drones\", \"uav\"],\n",
        "    \"penetration testing\": [\"penetration testing\"],\n",
        "    \"blockchain\": [\"blockchain\"],\n",
        "    \"cryptocurrency\": [\"cryptocurrency\", \"bitcoin\", \"ethereum\"],\n",
        "    \"quantum computing\": [\"quantum computing\"],\n",
        "    \"bioinformatics\": [\"bioinformatics\"],\n",
        "    \"digital twin\": [\"digital twin\"],\n",
        "    \"autonomous vehicles\": [\"autonomous vehicles\", \"self-driving cars\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzkEsy74nzlT"
      },
      "source": [
        "## Import necessary libraries\n",
        "____\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rsdg9Zi6nzlU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
            "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import PyPDF2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilsbawiunzlV"
      },
      "source": [
        "## Load SBERT model\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hLBCV9hYnzlV"
      },
      "outputs": [],
      "source": [
        "\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIhagfManzlW"
      },
      "source": [
        "## Load SpaCy model for lemmatization\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OQGfNxIunzlW"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBBfxevbnzlX"
      },
      "source": [
        "## Function to extract text from PDF\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tbp3-t3rnzlX"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(file_path):\n",
        "    text = ''\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogMqsnK6nzlY"
      },
      "source": [
        "## Function to lemmatize text and extract skills\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xf_YxokxnzlY"
      },
      "outputs": [],
      "source": [
        "def extract_skills_lemma(text):\n",
        "    doc = nlp(text.lower())\n",
        "    extracted_skills = set()\n",
        "    for token in doc:\n",
        "        for skill, lemmas in skill_lemma_dict.items():\n",
        "            if token.lemma_ in lemmas:\n",
        "                extracted_skills.add(skill)\n",
        "    return extracted_skills"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZntWtvpnzlZ"
      },
      "source": [
        "## Function to calculate similarity with SBERT\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gd0UPUcZnzla"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity_sbert(text1, text2):\n",
        "    # Encode the texts directly to embeddings\n",
        "    embeddings1 = sbert_model.encode([text1])\n",
        "    embeddings2 = sbert_model.encode([text2])\n",
        "\n",
        "    # Calculate cosine similarity without adding an extra list layer\n",
        "    similarity = cosine_similarity(embeddings1, embeddings2)[0][0]\n",
        "    return similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrD57f8Znzla"
      },
      "source": [
        "## Process Resumes and Job Description\n",
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_XEsgq2-nzlb",
        "outputId": "f4a5b3eb-333b-4910-f94d-013eb70ccf0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job Description Skills: {'java', 'css', 'javascript', 'sql', 'html', 'python'}\n",
            "Resume: SIDDHESH'S Resume.pdf\n",
            "Similarity Score: 0.4114\n",
            "Extracted Skills: {'mysql', 'react', 'c++', 'sql', 'convolutional neural networks', 'css', 'graphql', 'bootstrap', 'html', 'python'}\n",
            "\n",
            "Resume: Resume.pdf\n",
            "Similarity Score: 0.2971\n",
            "Extracted Skills: {'react', 'express', 'natural language processing', 'java', 'nosql', 'css', 'mongodb', 'tensorflow', 'javascript', 'bert', 'html', 'python', 'gpt'}\n",
            "\n",
            "Resume: ABHISHEK CV.pdf\n",
            "Similarity Score: 0.1912\n",
            "Extracted Skills: {'react', 'matplotlib', 'pandas', 'sql', 'numpy', 'css', 'bootstrap', 'javascript', 'html', 'leadership', 'python'}\n",
            "\n",
            "Resume: 94230796.pdf\n",
            "Similarity Score: 0.1513\n",
            "Extracted Skills: {'data analysis', 'communication', 'adaptability', 'teamwork', 'express'}\n",
            "\n",
            "Resume: 10247517.pdf\n",
            "Similarity Score: 0.1255\n",
            "Extracted Skills: {'data analysis', 'communication', 'c++', 'sql', 'leadership'}\n",
            "\n",
            "Resume: 10089434.pdf\n",
            "Similarity Score: 0.0540\n",
            "Extracted Skills: {'azure', 'kotlin', 'csharp', 'c++', 'sql', 'java', 'css', 'html'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def process_resumes_and_job_description(job_description, folder_path):\n",
        "    job_desc_text = job_description\n",
        "    job_desc_skills = extract_skills_lemma(job_desc_text)\n",
        "    print(f\"Job Description Skills: {job_desc_skills}\")\n",
        "\n",
        "    # Initialize a list to store tuples of (filename, similarity score, extracted skills)\n",
        "    resume_scores = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(folder_path, filename)\n",
        "            resume_text = extract_text_from_pdf(pdf_path)\n",
        "            resume_skills = extract_skills_lemma(resume_text)\n",
        "            similarity_score = calculate_similarity_sbert(job_desc_text, resume_text)\n",
        "\n",
        "            # Append a tuple with the necessary info to the list\n",
        "            resume_scores.append((filename, similarity_score, resume_skills))\n",
        "\n",
        "    # Sort the list of tuples by the similarity score in descending order\n",
        "    sorted_resumes = sorted(resume_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Print the sorted resumes\n",
        "    for filename, similarity_score, extracted_skills in sorted_resumes:\n",
        "        print(f\"Resume: {filename}\\nSimilarity Score: {similarity_score:.4f}\\nExtracted Skills: {extracted_skills}\\n\")\n",
        "\n",
        "job_description = \"SQL, javascript, HTML, Java, CSS,python\"\n",
        "folder_path = \"C:/Users/DELL/Desktop/infogen intern/task4_resume/resumes1\"  \n",
        "process_resumes_and_job_description(job_description, folder_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
